{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка корпуса Taiga\n",
    "\n",
    "Формирование и проверка корпуса, сохраняем в `taiga_style_dataset.csv` для `style_boosted_pipeline.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e4536b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовые импорты (без try/except, дисциплина превыше всего)\n",
    "from __future__ import annotations\n",
    "import inspect\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tarfile\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from functools import lru_cache\n",
    "import warnings\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterable, List, Optional, Sequence, Tuple\n",
    "# Backport inspect.getargspec removed in Python 3.11 for pymorphy2 compatibility\n",
    "if not hasattr(inspect, \"getargspec\"):\n",
    "    from collections import namedtuple\n",
    "    ArgSpec = namedtuple(\"ArgSpec\", [\"args\", \"varargs\", \"keywords\", \"defaults\"])\n",
    "    def _getargspec(func):\n",
    "        spec = inspect.getfullargspec(func)\n",
    "        return ArgSpec(spec.args, spec.varargs, spec.varkw, spec.defaults)\n",
    "    inspect.getargspec = _getargspec  # type: ignore[attr-defined]\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from lightgbm import LGBMClassifier\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedaeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Глобальные настройки предупреждений\n",
    "warnings.filterwarnings(\"ignore\", message=\"pkg_resources is deprecated\")\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"No further splits with positive gain\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973746c3",
   "metadata": {},
   "source": [
    "## Конфигурация и контрольные параметры\n",
    "глобальные параметры, пути к данным и отладочные флаги, используемые при сборке корпуса.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1964ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_flag = os.environ.get(\"STYLE_PIPELINE_DEBUG\", \"0\").lower() not in {\"0\", \"false\", \"no\"}\n",
    "debug_sample_env = os.environ.get(\"STYLE_PIPELINE_DEBUG_SIZE\", \"\")\n",
    "try:\n",
    "    debug_sample_size = int(debug_sample_env) if debug_sample_env else 600\n",
    "except ValueError:\n",
    "    debug_sample_size = 600\n",
    "# Основной конфигурационный словарь: управляет путями, объёмами данных и гиперпараметрами\n",
    "config: Dict[str, object] = {\n",
    "    \"DATA_DIR\": Path(\"./data\"),\n",
    "    \"DATASET_FILENAME\": \"taiga_style_dataset.csv\",\n",
    "    \"TARGET_COLUMN\": \"label\",\n",
    "    \"TEXT_COLUMN\": \"text\",\n",
    "    \"HINT_COLUMN\": \"style_hint_label\",\n",
    "    \"HINT_NAME_COLUMN\": \"style_hint\",\n",
    "    \"HINT_CONFIDENCE_COLUMN\": \"style_hint_confidence\",\n",
    "    \"TEST_SIZE\": 0.2,\n",
    "    \"VAL_SIZE\": 0.2,\n",
    "    \"MIN_TEXT_LENGTH\": 10,\n",
    "    \"RANDOM_STATE\": 2024,\n",
    "    \"CACHE_DIR\": Path(\"./cache_boosted\"),\n",
    "    \"N_JOBS\": os.cpu_count() or 4,\n",
    "    \"REBUILD_DATASET\": True,  # True → пересобрать корпус из архивов, False → использовать готовый CSV\n",
    "    \"SEGMENT_MAX_CHARS\": 380,\n",
    "    \"SEGMENT_MIN_CHARS\": 10,\n",
    "    \"SEGMENT_MAX_PER_FILE\": 6,\n",
    "    \"DATASET_BALANCE_PER_CLASS\": 8000, #8000\n",
    "    \"STYLE_LABELS\": {\n",
    "        0: \"разговорный стиль\",\n",
    "        1: \"официально-деловой стиль\",\n",
    "    },\n",
    "    \"RAW_SOURCES\": [  # описание каждого архива: путь, фильтры, эвристический hint\n",
    "        # Subtitles: разговорный стиль (корпус субтитров)\n",
    "        # {\n",
    "            # \"name\": \"Subtitles\",\n",
    "            # \"kind\": \"subtitles\",\n",
    "            # \"archive\": \"Subtitles.tar.gz\",\n",
    "            # \"metadata_member\": \"home/tsha/Subtitles/metatable.csv\",\n",
    "            # \"text_base\": \"home/tsha/Subtitles/texts\",\n",
    "            # \"style_hint\": 0,\n",
    "            # \"hint_confidence\": 0.65,\n",
    "            # \"hint_source\": \"archive\",\n",
    "            # \"max_files\": 500, #4500\n",
    "            # \"languages\": [\"ru\"],\n",
    "        # },\n",
    "        # Interfax: официальные новости\n",
    "        {\n",
    "            \"name\": \"Interfax\",\n",
    "            \"kind\": \"interfax\",\n",
    "            \"archive\": \"Interfax.tar.gz\",\n",
    "            \"metadata_member\": \"home/tsha/Interfax/newmetadata.csv\",\n",
    "            \"text_base\": \"home/tsha/Interfax/texts\",\n",
    "            \"style_hint\": 1,\n",
    "            \"hint_confidence\": 0.75,\n",
    "            \"hint_source\": \"archive\",\n",
    "            \"max_files\": 10000, #5000\n",
    "        },\n",
    "        # Social: сообщения из соцсетей\n",
    "        {\n",
    "            \"name\": \"Social\",\n",
    "            \"kind\": \"social\",\n",
    "            \"archive\": \"social.tar.gz\",\n",
    "            \"text_members\": [\n",
    "                \"home/tsha/social/texts/vktexts.txt\",\n",
    "                \"home/tsha/social/texts/fbtexts.txt\",\n",
    "                \"home/tsha/social/texts/LiveJournalPostsandcommentsGICR.txt\",\n",
    "                \"home/tsha/social/texts/twtexts.txt\",\n",
    "            ],\n",
    "            \"style_hint\": 0,\n",
    "            \"hint_confidence\": 0.6,\n",
    "            \"hint_source\": \"archive\",\n",
    "            \"max_records\": 6000, #15000\n",
    "        },\n",
    "        # Arzamas: научно-популярные тексты\n",
    "        # {\n",
    "            # \"name\": \"Arzamas\",\n",
    "            # \"kind\": \"arzamas\",\n",
    "            # \"archive\": \"Arzamas.tar.gz\",\n",
    "            # \"metadata_member\": \"home/tsha/Arzamas/metatable.csv\",\n",
    "            # \"text_base\": \"home/tsha/Arzamas/texts\",\n",
    "            # \"style_hint\": 1,\n",
    "            # \"hint_confidence\": 0.7,\n",
    "            # \"hint_source\": \"archive\",\n",
    "            # \"max_files\": 600, # 4000\n",
    "        # },\n",
    "    ],\n",
    "    \"MAX_FEATURES_WORD\": 120000,\n",
    "    \"MAX_FEATURES_CHAR\": 60000,\n",
    "    \"WORD_NGRAM_RANGE\": (1, 3),\n",
    "    \"CHAR_NGRAM_RANGE\": (3, 5),\n",
    "    \"MIN_DF_WORD\": 3,\n",
    "    \"MIN_DF_CHAR\": 2,\n",
    "    \"TF_SUBLINEAR\": True,\n",
    "    \"LOGREG_SEARCH_ITER\": 10, #30\n",
    "    \"SGD_SEARCH_ITER\": 10, #25\n",
    "    \"CV_FOLDS\": 5,\n",
    "    \"MAX_ITER_LINEAR\": 200,\n",
    "    \"WORD2VEC_DIM\": 200,\n",
    "    \"WORD2VEC_WINDOW\": 5,\n",
    "    \"WORD2VEC_MIN_COUNT\": 2,\n",
    "    \"SEQUENCE_MAX_LEN\": 256,\n",
    "    \"BATCH_SIZE\": 64, #128\n",
    "    \"SEQUENCE_EPOCHS\": 10, #10-12\n",
    "    \"LEARNING_RATE\": 1e-3,\n",
    "    \"EMBEDDING_DROPOUT\": 0.3,\n",
    "    \"GRAD_CLIP\": 1.5,\n",
    "    \"ENSEMBLE_WEIGHT_GRID\": 21,\n",
    "    \"TEXTCNN_KERNEL_SIZES\": [2, 3, 4],\n",
    "    \"TEXTCNN_FILTERS\": 256,\n",
    "    \"BILSTM_HIDDEN_SIZE\": 192,\n",
    "    \"BILSTM_NUM_LAYERS\": 2,\n",
    "    \"LGBM_N_ESTIMATORS\": 800,\n",
    "    \"LGBM_LEARNING_RATE\": 0.05,\n",
    "    \"LGBM_SUBSAMPLE\": 0.8,\n",
    "    \"LGBM_COLSAMPLE\": 0.8,\n",
    "    \"LGBM_REG_ALPHA\": 0.1,\n",
    "    \"LGBM_REG_LAMBDA\": 0.3,\n",
    "    \"EXTRATREES_N_ESTIMATORS\": 600,\n",
    "    \"EXTRATREES_MIN_SAMPLES_SPLIT\": 5,\n",
    "    \"EXTRATREES_MIN_SAMPLES_LEAF\": 2,\n",
    "    \"FEATURE_UNION_PKL\": Path(\"./cache_boosted/feature_union.joblib\"),\n",
    "    \"LOGREG_PKL\": Path(\"./cache_boosted/logreg_elasticnet.joblib\"),\n",
    "    \"SGD_PKL\": Path(\"./cache_boosted/sgd_elasticnet.joblib\"),\n",
    "    \"WORD2VEC_MODEL\": Path(\"./cache_boosted/word2vec.model\"),\n",
    "    \"RESULTS_CSV\": Path(\"./cache_boosted/model_results.csv\"),\n",
    "    \"TEXTCNN_STATE_PATH\": Path(\"./cache_boosted/textcnn_state.pt\"),\n",
    "    \"BILSTM_STATE_PATH\": Path(\"./cache_boosted/bilstm_state.pt\"),\n",
    "    \"LABEL_INDEX_JSON\": Path(\"./cache_boosted/label_index.json\"),\n",
    "    \"SEQUENCE_VOCAB_JSON\": Path(\"./cache_boosted/sequence_vocab.json\"),\n",
    "    \"ENSEMBLE_ERRORS_CSV\": Path(\"./data/misclassified_ensemble.csv\"),\n",
    "    \"DEBUG_MODE\": debug_flag,\n",
    "    \"DEBUG_SAMPLE_SIZE\": debug_sample_size,\n",
    "}\n",
    "if config[\"DEBUG_SAMPLE_SIZE\"] <= 0:\n",
    "    config[\"DEBUG_SAMPLE_SIZE\"] = 600\n",
    "if config[\"DEBUG_MODE\"]:\n",
    "    config[\"LOGREG_SEARCH_ITER\"] = min(5, config[\"LOGREG_SEARCH_ITER\"])\n",
    "    config[\"SGD_SEARCH_ITER\"] = min(5, config[\"SGD_SEARCH_ITER\"])\n",
    "    config[\"CV_FOLDS\"] = min(3, config[\"CV_FOLDS\"])\n",
    "    config[\"MAX_ITER_LINEAR\"] = min(100, config[\"MAX_ITER_LINEAR\"])\n",
    "    config[\"MAX_FEATURES_WORD\"] = min(30000, config[\"MAX_FEATURES_WORD\"])\n",
    "    config[\"MAX_FEATURES_CHAR\"] = min(15000, config[\"MAX_FEATURES_CHAR\"])\n",
    "    config[\"WORD2VEC_MIN_COUNT\"] = 1\n",
    "    config[\"WORD2VEC_WINDOW\"] = min(3, config[\"WORD2VEC_WINDOW\"])\n",
    "    config[\"SEQUENCE_MAX_LEN\"] = min(128, config[\"SEQUENCE_MAX_LEN\"])\n",
    "    config[\"BATCH_SIZE\"] = min(64, config[\"BATCH_SIZE\"])\n",
    "    config[\"SEQUENCE_EPOCHS\"] = min(3, config[\"SEQUENCE_EPOCHS\"])\n",
    "    config[\"ENSEMBLE_WEIGHT_GRID\"] = min(11, config[\"ENSEMBLE_WEIGHT_GRID\"])\n",
    "    config[\"LGBM_N_ESTIMATORS\"] = min(200, config[\"LGBM_N_ESTIMATORS\"])\n",
    "    config[\"EXTRATREES_N_ESTIMATORS\"] = min(200, config[\"EXTRATREES_N_ESTIMATORS\"])\n",
    "    config[\"TEXTCNN_FILTERS\"] = min(128, config[\"TEXTCNN_FILTERS\"])\n",
    "    config[\"BILSTM_HIDDEN_SIZE\"] = min(128, config[\"BILSTM_HIDDEN_SIZE\"])\n",
    "    config[\"N_JOBS\"] = 1\n",
    "    config[\"DATASET_BALANCE_PER_CLASS\"] = min(600, config[\"DATASET_BALANCE_PER_CLASS\"])\n",
    "    for source in config[\"RAW_SOURCES\"]:\n",
    "        if \"max_files\" in source:\n",
    "            source[\"max_files\"] = min(source[\"max_files\"], config[\"DEBUG_SAMPLE_SIZE\"])\n",
    "        if \"max_records\" in source:\n",
    "            source[\"max_records\"] = min(source[\"max_records\"], config[\"DEBUG_SAMPLE_SIZE\"] * 2)\n",
    "config[\"DATA_DIR\"].mkdir(parents=True, exist_ok=True)\n",
    "config[\"CACHE_DIR\"].mkdir(parents=True, exist_ok=True)\n",
    "# Путь до csv с готовым корпусом\n",
    "config[\"DATASET_CSV\"] = config[\"DATA_DIR\"] / config[\"DATASET_FILENAME\"]\n",
    "for source in config[\"RAW_SOURCES\"]:\n",
    "    archive_path = Path(source[\"archive\"])\n",
    "    if not archive_path.is_absolute():\n",
    "        archive_path = config[\"DATA_DIR\"] / archive_path\n",
    "    source[\"archive_path\"] = archive_path\n",
    "# Генератор случайных чисел для воспроизводимости\n",
    "random_state = check_random_state(config[\"RANDOM_STATE\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28258176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции подготовки корпуса вынесены в src.data_prep\n",
    "from src.data_prep import (\n",
    "    build_dataset_from_sources,\n",
    "    compute_corpus_summary,\n",
    "    write_corpus_report,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc4b5316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db24b90ffc840d49735cc582748bd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:06:16] </span><span style=\"color: #008000; text-decoration-color: #008000\">Interfax: добавлено </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">27255</span><span style=\"color: #008000; text-decoration-color: #008000\"> сегментов</span>                                                       <a href=\"file:///home/count/code/hw_nlp/src/data_prep/sources.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sources.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/count/code/hw_nlp/src/data_prep/sources.py#785\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">785</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11:06:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mInterfax: добавлено \u001b[0m\u001b[1;32m27255\u001b[0m\u001b[32m сегментов\u001b[0m                                                       \u001b]8;id=733988;file:///home/count/code/hw_nlp/src/data_prep/sources.py\u001b\\\u001b[2msources.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=242128;file:///home/count/code/hw_nlp/src/data_prep/sources.py#785\u001b\\\u001b[2m785\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[11:06:54] </span><span style=\"color: #008000; text-decoration-color: #008000\">Social: добавлено </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">306206</span><span style=\"color: #008000; text-decoration-color: #008000\"> сегментов</span>                                                        <a href=\"file:///home/count/code/hw_nlp/src/data_prep/sources.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">sources.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/count/code/hw_nlp/src/data_prep/sources.py#785\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">785</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[11:06:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mSocial: добавлено \u001b[0m\u001b[1;32m306206\u001b[0m\u001b[32m сегментов\u001b[0m                                                        \u001b]8;id=595616;file:///home/count/code/hw_nlp/src/data_prep/sources.py\u001b\\\u001b[2msources.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=260748;file:///home/count/code/hw_nlp/src/data_prep/sources.py#785\u001b\\\u001b[2m785\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет собран заново: 16000 строк -> data/taiga_style_dataset.csv\n",
      "  Interfax: 27255\n",
      "  Social: 306206\n"
     ]
    }
   ],
   "source": [
    "if config.get(\"REBUILD_DATASET\") or not config[\"DATASET_CSV\"].exists():\n",
    "    dataset_built = build_dataset_from_sources(config)\n",
    "    dataset_built.to_csv(config[\"DATASET_CSV\"], index=False)\n",
    "    print(f\"Датасет собран заново: {len(dataset_built)} строк -> {config['DATASET_CSV']}\")\n",
    "    for name, size in config.get('SOURCE_STATS', []):\n",
    "        print(f\"  {name}: {size}\")\n",
    "else:\n",
    "    print(f\"Используем существующий датасет: {config['DATASET_CSV']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd49c47",
   "metadata": {},
   "source": [
    "## Загрузка и первичная проверка корпуса\n",
    "\n",
    "Проверка обязательные столбцов, очищстка пропусков и фиксируем исходную статистику корпуса.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d68d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Колонка label отсутствует в корпусе. Заполнено значением -1 (будет проставлено после авторазметки).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not config[\"DATASET_CSV\"].exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Не найден файл {config['DATASET_CSV']}. Скопируйте датасет и запустите ячейку повторно.\"\n",
    "    )\n",
    "\n",
    "df = pd.read_csv(config[\"DATASET_CSV\"], encoding=\"utf-8\")\n",
    "if config[\"TARGET_COLUMN\"] not in df.columns:\n",
    "    df[config[\"TARGET_COLUMN\"]] = -1\n",
    "    print(\n",
    "        f\"Колонка {config['TARGET_COLUMN']} отсутствует в корпусе. Заполнено значением -1 (будет проставлено после авторазметки).\"\n",
    "    )\n",
    "\n",
    "required_columns = {config[\"TEXT_COLUMN\"]}\n",
    "missing_columns = required_columns.difference(df.columns)\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"В датасете отсутствуют необходимые колонки: {sorted(missing_columns)}\")\n",
    "\n",
    "df = df.dropna(subset=[config[\"TEXT_COLUMN\"]]).copy()\n",
    "df[config[\"TEXT_COLUMN\"]] = df[config[\"TEXT_COLUMN\"]].astype(str)\n",
    "\n",
    "corpus_stats: Dict[str, object] = {}\n",
    "corpus_stats[\"initial_rows\"] = int(len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74116f6",
   "metadata": {},
   "source": [
    "## Очистка корпуса и оценка шума\n",
    "\n",
    "удаляем дубликаты и короткие тексты, при необходимости формируем отладочную выборку и обновляем показатели `corpus_stats`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefae420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deduplicated = df.drop_duplicates(subset=[config[\"TEXT_COLUMN\"]], keep=\"first\").copy()\n",
    "removed_duplicates = corpus_stats[\"initial_rows\"] - len(deduplicated)\n",
    "\n",
    "length_mask = deduplicated[config[\"TEXT_COLUMN\"]].str.len() >= config[\"MIN_TEXT_LENGTH\"]\n",
    "clean_df = deduplicated.loc[length_mask].copy()\n",
    "removed_invalid = len(deduplicated) - len(clean_df)\n",
    "\n",
    "clean_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "corpus_stats[\"removed_duplicates\"] = int(removed_duplicates)\n",
    "corpus_stats[\"removed_invalid\"] = int(removed_invalid)\n",
    "corpus_stats[\"final_rows\"] = int(len(clean_df))\n",
    "corpus_stats[\"noise_share\"] = round((removed_duplicates + removed_invalid) / corpus_stats[\"initial_rows\"], 4)\n",
    "\n",
    "if config[\"DEBUG_MODE\"] and len(clean_df) > config[\"DEBUG_SAMPLE_SIZE\"]:\n",
    "    sample_size = max(1, min(config[\"DEBUG_SAMPLE_SIZE\"], len(clean_df)))\n",
    "    clean_df = clean_df.sample(n=sample_size, random_state=config[\"RANDOM_STATE\"], replace=False).reset_index(drop=True)\n",
    "    corpus_stats[\"debug_sample_size\"] = int(sample_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6925b9e4",
   "metadata": {},
   "source": [
    "## Итоговая проверка корпуса\n",
    "\n",
    "метрики по корпусу, ключевые срезы и сохраняем отчёты в каталоге `reports`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7b8843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rows",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "unique_texts",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "duplicates_removed",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2a2df686-d2a8-424e-89a1-3eee9ce7b9b6",
       "rows": [
        [
         "corpus",
         "16000",
         "16000",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>unique_texts</th>\n",
       "      <th>duplicates_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>corpus</th>\n",
       "      <td>16000</td>\n",
       "      <td>16000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rows  unique_texts  duplicates_removed\n",
       "corpus  16000         16000                   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "median",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "p95",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "29f46927-e804-4072-9910-d17b417c4c79",
       "rows": [
        [
         "length",
         "12.0",
         "380.0",
         "222.5759375",
         "234.0",
         "368.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>p95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>12.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>222.575938</td>\n",
       "      <td>234.0</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         min    max        mean  median    p95\n",
       "length  12.0  380.0  222.575938   234.0  368.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "hint_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "share",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ba98fbe2-b508-4938-911a-62fa3574bb33",
       "rows": [
        [
         "0",
         "8000",
         "0.5"
        ],
        [
         "1",
         "8000",
         "0.5"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hint_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count  share\n",
       "hint_label              \n",
       "0            8000    0.5\n",
       "1            8000    0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "share",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "da2063fd-39bd-486e-9cf1-d5926e98f7f7",
       "rows": [
        [
         "-1",
         "16000",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>16000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  share\n",
       "label              \n",
       "-1     16000    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёты сохранены в:\n",
      "  json: cache_boosted/reports/taiga_style_dataset_report.json\n",
      "  markdown: cache_boosted/reports/taiga_style_dataset_report.md\n",
      "  csv: cache_boosted/reports/taiga_style_dataset_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary = compute_corpus_summary(\n",
    "    clean_df,\n",
    "    text_column=config[\"TEXT_COLUMN\"],\n",
    "    label_column=config[\"TARGET_COLUMN\"],\n",
    "    hint_column=config.get(\"HINT_COLUMN\"),\n",
    "    source_stats=config.get(\"SOURCE_STATS\"),\n",
    ")\n",
    "headline = pd.Series(\n",
    "    {\n",
    "        'rows': summary['rows'],\n",
    "        'unique_texts': summary['unique_texts'],\n",
    "        'duplicates_removed': summary['duplicates_removed'],\n",
    "    }\n",
    ", name='corpus')\n",
    "display(headline.to_frame().T)\n",
    "length_stats = pd.Series(summary['length']).to_frame().T\n",
    "length_stats.index = ['length']\n",
    "display(length_stats)\n",
    "if summary.get('hints'):\n",
    "    hint_frame = (\n",
    "        pd.DataFrame.from_dict(summary['hints'], orient='index')\n",
    "        .rename_axis('hint_label')\n",
    "    )\n",
    "    display(hint_frame)\n",
    "label_frame = (\n",
    "    pd.DataFrame.from_dict(summary['labels'], orient='index')\n",
    "    .rename_axis('label')\n",
    ")\n",
    "display(label_frame)\n",
    "reports_dir = config['CACHE_DIR'] / 'reports'\n",
    "report_paths = write_corpus_report(summary, reports_dir, report_name=config['DATASET_CSV'].stem)\n",
    "corpus_stats['report_paths'] = {kind: str(path) for kind, path in report_paths.items()}\n",
    "print('Отчёты сохранены в:')\n",
    "for kind, path in report_paths.items():\n",
    "    print(f'  {kind}: {path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
