{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Авторазметка стилей: zero-shot → BERT\n",
    "\n",
    "Ноутбук строит автоматический pipeline для разметки корпуса:\n",
    "1. Небольшой seed датасет собирается с помощью zero-shot/LLM (через HuggingFace).\n",
    "2. На seed обучается компактная BERT-модель, которая переносит метки на весь корпус.\n",
    "3. Отбираются сомнительные примеры для активного уточнения (ручная проверка или вызов LLM второй волной)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты и подготовка окружения\n",
    "\n",
    "Убедитесь, что установлены пакеты `transformers`, `accelerate`, `datasets`, `torch`, `tqdm`, `scikit-learn`. В VRAM ≈12 ГБ удобно работать с моделями до 110 M параметров (RuBERT, MiniLM и др.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf63aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ['TRANSFORMERS_NO_TF'] = '1'\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dc662d",
   "metadata": {},
   "source": [
    "## Конфигурация автозаметчика\n",
    "\n",
    "Все артефакты складываем в `cache_boosted/autolabel`. Zero-shot модель можно заменить на любую подходящую для русского языка (`cointegrated/rubert-tiny2`, `MoravecLab/zero-shot-classifier-rus`, `joeddav/xlm-roberta-large-xnli`, и т. д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea6be018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASET_CSV': PosixPath('data/taiga_style_dataset.csv'),\n",
       " 'TEXT_COLUMN': 'text',\n",
       " 'HINT_COLUMN': 'style_hint_label',\n",
       " 'HINT_NAME_COLUMN': 'style_hint',\n",
       " 'HINT_CONFIDENCE_COLUMN': 'style_hint_confidence',\n",
       " 'ZERO_SHOT_MODELS': ['joeddav/xlm-roberta-large-xnli',\n",
       "  'facebook/bart-large-mnli',\n",
       "  'cointegrated/rubert-tiny2',\n",
       "  'DeepPavlov/rubert-base-cased'],\n",
       " 'ZERO_SHOT_MODEL': 'cointegrated/rubert-tiny2',\n",
       " 'ZERO_SHOT_SAMPLE_SIZE': 3000,\n",
       " 'ZERO_SHOT_THRESHOLD': 0.48,\n",
       " 'LABEL_NAMES': {0: 'разговорный стиль', 1: 'официально-деловой стиль'},\n",
       " 'BERT_BASE_MODEL': 'ai-forever/ruBert-base',\n",
       " 'MAX_LENGTH': 256,\n",
       " 'TRAIN_SIZE': 0.85,\n",
       " 'SEED': 2024,\n",
       " 'PSEUDO_MIN_CONF': 0.7}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUTOLABEL_DIR = Path(\"cache_boosted/autolabel\")\n",
    "AUTOLABEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Настройки сгруппированы по смыслу. Меняйте значения из подписанных блоков,\n",
    "# остальное оставлено по умолчанию для воспроизводимости.\n",
    "config: Dict[str, object] = {\n",
    "    # --- Данные ---\n",
    "    \"DATASET_CSV\": Path(\"data/taiga_style_dataset.csv\"),  # корпус из style_dataset_preparation.ipynb\n",
    "    \"TEXT_COLUMN\": \"text\",\n",
    "    \"HINT_COLUMN\": \"style_hint_label\",\n",
    "    \"HINT_NAME_COLUMN\": \"style_hint\",\n",
    "    \"HINT_CONFIDENCE_COLUMN\": \"style_hint_confidence\",\n",
    "\n",
    "    # --- Подбор zero-shot ---\n",
    "    \"ZERO_SHOT_MODELS\": [  # кандидаты; добавьте свои при необходимости\n",
    "        \"joeddav/xlm-roberta-large-xnli\",\n",
    "        \"facebook/bart-large-mnli\",\n",
    "        \"cointegrated/rubert-tiny2\",\n",
    "        \"DeepPavlov/rubert-base-cased\",\n",
    "    ],\n",
    "    \"ZERO_SHOT_MODEL\": \"cointegrated/rubert-tiny2\",  # будет переопределён по результатам оценки\n",
    "    \"ZERO_SHOT_SAMPLE_SIZE\": 3000,  # сколько примеров берём для оценки кандидатов\n",
    "    \"ZERO_SHOT_THRESHOLD\": 0.48,  # ↑ делает seed чище, но меньше (рекомендовано 0.45–0.6)\n",
    "\n",
    "    # --- Обучение компактного BERT ---\n",
    "    \"LABEL_NAMES\": {\n",
    "        0: \"разговорный стиль\",\n",
    "        1: \"официально-деловой стиль\",\n",
    "    },\n",
    "    \"BERT_BASE_MODEL\": \"ai-forever/ruBert-base\",  # можно заменить на любой rus BERT\n",
    "    \"MAX_LENGTH\": 256,  # длина токенов для BERT (256 для экономии VRAM, 512 для макс. качества)\n",
    "    \"TRAIN_SIZE\": 0.85,  # доля train от seed (остальное -> val)\n",
    "\n",
    "    # --- Повторяемость и фильтры ---\n",
    "    \"SEED\": 2024,\n",
    "    \"PSEUDO_MIN_CONF\": 0.70,  # отбрасываем псевдометки ниже порога перед сохранением\n",
    "}\n",
    "random.seed(config[\"SEED\"])\n",
    "np.random.seed(config[\"SEED\"])\n",
    "torch.manual_seed(config[\"SEED\"])\n",
    "config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7b720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корпус: 16000 сегментов\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "style_hint_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "rows",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "e5028819-63dd-48ec-8344-eba070373ab8",
       "rows": [
        [
         "0",
         "8000"
        ],
        [
         "1",
         "8000"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "style_hint_label\n",
       "0    8000\n",
       "1    8000\n",
       "Name: rows, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_archive",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "meta_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "meta_title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_languages",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "meta_textid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_rubric",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_region",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "meta_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_tags",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "style_hint_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "style_hint",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "style_hint_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "style_hint_source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "cd9cad29-6ba4-4f5f-a7d9-bb831c78526e",
       "rows": [
        [
         "0",
         "Кто против ЕР с сотней Казаков подъедем пошукаем кто зачинщик и нагайками забьем",
         "social.tar.gz",
         "home/tsha/social/texts/vktexts.txt#entry162588",
         "162588",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "разговорный стиль",
         "0.6",
         "archive"
        ],
        [
         "1",
         "На 36-й минуте игры с \"Зенитом\" во вратаря \"Динамо\" попала петарда, брошенная с сектора, где располагались фанаты команды гостей. Матч был прерван и остался недоигранным. В больнице Шунину был поставлен диагноз - химический ожог роговицы, век и конъюнктив обоих глаз, а также посттравматический отит правого уха со снижением слуха.",
         "Interfax.tar.gz",
         "home/tsha/Interfax/texts/sport277931.txt",
         "sport277931",
         "Вратарю &quot;Динамо&quot; Шунину разрешили тренироваться в общей группе",
         null,
         "sport277931",
         "Спорт",
         null,
         "2012-11-27",
         "футбол",
         "1",
         "официально-деловой стиль",
         "0.75",
         "archive"
        ],
        [
         "2",
         "Пора прекратить размахивать Ядерной Дубиной!",
         "social.tar.gz",
         "home/tsha/social/texts/vktexts.txt#entry284914",
         "284914",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "разговорный стиль",
         "0.6",
         "archive"
        ],
        [
         "3",
         "Теги: футбол, Лига чемпионов, Спартак, травма",
         "Interfax.tar.gz",
         "home/tsha/Interfax/texts/sport261719.txt",
         "sport261719",
         "Футболисты &quot;Спартака&quot; Ромулу, Пареха и Чельстрем пройдут в четверг медобследование",
         null,
         "sport261719",
         "Спорт",
         null,
         "2012-08-22",
         "футбол",
         "1",
         "официально-деловой стиль",
         "0.75",
         "archive"
        ],
        [
         "4",
         "Предвыборный штаб кандидата в президенты Владимира Путина в период, оставшийся до президентских выборов, не планирует проводить новых массовых мероприятий в поддержку своего кандидата, сообщил журналистам заместитель главы штаба Павел Зенькович. \"В оставшееся до выборов время штаб не планирует подавать заявки на проведение новых шествий и митингов\", - сказал П.Зенькович.",
         "Interfax.tar.gz",
         "home/tsha/Interfax/texts/russia232337.txt",
         "russia232337",
         "Предвыборный штаб Путина в оставшееся до 4 марта время не планирует новых мероприятий",
         null,
         "russia232337",
         "В России",
         null,
         "2012-02-23",
         "Выборы",
         "1",
         "официально-деловой стиль",
         "0.75",
         "archive"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source_archive</th>\n",
       "      <th>source_file</th>\n",
       "      <th>meta_id</th>\n",
       "      <th>meta_title</th>\n",
       "      <th>meta_languages</th>\n",
       "      <th>meta_textid</th>\n",
       "      <th>meta_rubric</th>\n",
       "      <th>meta_region</th>\n",
       "      <th>meta_date</th>\n",
       "      <th>meta_tags</th>\n",
       "      <th>style_hint_label</th>\n",
       "      <th>style_hint</th>\n",
       "      <th>style_hint_confidence</th>\n",
       "      <th>style_hint_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Кто против ЕР с сотней Казаков подъедем пошука...</td>\n",
       "      <td>social.tar.gz</td>\n",
       "      <td>home/tsha/social/texts/vktexts.txt#entry162588</td>\n",
       "      <td>162588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.60</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>На 36-й минуте игры с \"Зенитом\" во вратаря \"Ди...</td>\n",
       "      <td>Interfax.tar.gz</td>\n",
       "      <td>home/tsha/Interfax/texts/sport277931.txt</td>\n",
       "      <td>sport277931</td>\n",
       "      <td>Вратарю &amp;quot;Динамо&amp;quot; Шунину разрешили тр...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sport277931</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>футбол</td>\n",
       "      <td>1</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0.75</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Пора прекратить размахивать Ядерной Дубиной!</td>\n",
       "      <td>social.tar.gz</td>\n",
       "      <td>home/tsha/social/texts/vktexts.txt#entry284914</td>\n",
       "      <td>284914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.60</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Теги: футбол, Лига чемпионов, Спартак, травма</td>\n",
       "      <td>Interfax.tar.gz</td>\n",
       "      <td>home/tsha/Interfax/texts/sport261719.txt</td>\n",
       "      <td>sport261719</td>\n",
       "      <td>Футболисты &amp;quot;Спартака&amp;quot; Ромулу, Пареха...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sport261719</td>\n",
       "      <td>Спорт</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-08-22</td>\n",
       "      <td>футбол</td>\n",
       "      <td>1</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0.75</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Предвыборный штаб кандидата в президенты Влади...</td>\n",
       "      <td>Interfax.tar.gz</td>\n",
       "      <td>home/tsha/Interfax/texts/russia232337.txt</td>\n",
       "      <td>russia232337</td>\n",
       "      <td>Предвыборный штаб Путина в оставшееся до 4 мар...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>russia232337</td>\n",
       "      <td>В России</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-02-23</td>\n",
       "      <td>Выборы</td>\n",
       "      <td>1</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0.75</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   source_archive  \\\n",
       "0  Кто против ЕР с сотней Казаков подъедем пошука...    social.tar.gz   \n",
       "1  На 36-й минуте игры с \"Зенитом\" во вратаря \"Ди...  Interfax.tar.gz   \n",
       "2       Пора прекратить размахивать Ядерной Дубиной!    social.tar.gz   \n",
       "3      Теги: футбол, Лига чемпионов, Спартак, травма  Interfax.tar.gz   \n",
       "4  Предвыборный штаб кандидата в президенты Влади...  Interfax.tar.gz   \n",
       "\n",
       "                                      source_file       meta_id  \\\n",
       "0  home/tsha/social/texts/vktexts.txt#entry162588        162588   \n",
       "1        home/tsha/Interfax/texts/sport277931.txt   sport277931   \n",
       "2  home/tsha/social/texts/vktexts.txt#entry284914        284914   \n",
       "3        home/tsha/Interfax/texts/sport261719.txt   sport261719   \n",
       "4       home/tsha/Interfax/texts/russia232337.txt  russia232337   \n",
       "\n",
       "                                          meta_title  meta_languages  \\\n",
       "0                                                NaN             NaN   \n",
       "1  Вратарю &quot;Динамо&quot; Шунину разрешили тр...             NaN   \n",
       "2                                                NaN             NaN   \n",
       "3  Футболисты &quot;Спартака&quot; Ромулу, Пареха...             NaN   \n",
       "4  Предвыборный штаб Путина в оставшееся до 4 мар...             NaN   \n",
       "\n",
       "    meta_textid meta_rubric  meta_region   meta_date meta_tags  \\\n",
       "0           NaN         NaN          NaN         NaN       NaN   \n",
       "1   sport277931       Спорт          NaN  2012-11-27    футбол   \n",
       "2           NaN         NaN          NaN         NaN       NaN   \n",
       "3   sport261719       Спорт          NaN  2012-08-22    футбол   \n",
       "4  russia232337    В России          NaN  2012-02-23    Выборы   \n",
       "\n",
       "   style_hint_label                style_hint  style_hint_confidence  \\\n",
       "0                 0         разговорный стиль                   0.60   \n",
       "1                 1  официально-деловой стиль                   0.75   \n",
       "2                 0         разговорный стиль                   0.60   \n",
       "3                 1  официально-деловой стиль                   0.75   \n",
       "4                 1  официально-деловой стиль                   0.75   \n",
       "\n",
       "  style_hint_source  \n",
       "0           archive  \n",
       "1           archive  \n",
       "2           archive  \n",
       "3           archive  \n",
       "4           archive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not config[\"DATASET_CSV\"].exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Не найден {config['DATASET_CSV']}. Перед авторазметкой выполните подготовку корпуса.\"\n",
    "    )\n",
    "\n",
    "raw_df = pd.read_csv(config[\"DATASET_CSV\"], encoding=\"utf-8\")\n",
    "raw_df = raw_df.dropna(subset=[config[\"TEXT_COLUMN\"]]).copy()\n",
    "raw_df[config[\"TEXT_COLUMN\"]] = raw_df[config[\"TEXT_COLUMN\"]].astype(str)\n",
    "\n",
    "hint_col = config.get(\"HINT_COLUMN\")\n",
    "if hint_col:\n",
    "    if hint_col in raw_df.columns:\n",
    "        raw_df[hint_col] = raw_df[hint_col].fillna(-1).astype(int)\n",
    "    else:\n",
    "        raw_df[hint_col] = -1\n",
    "\n",
    "hint_name_col = config.get(\"HINT_NAME_COLUMN\")\n",
    "if hint_name_col:\n",
    "    if hint_name_col in raw_df.columns:\n",
    "        raw_df[hint_name_col] = raw_df[hint_name_col].fillna(\"\").astype(str)\n",
    "    else:\n",
    "        raw_df[hint_name_col] = \"\"\n",
    "\n",
    "hint_conf_col = config.get(\"HINT_CONFIDENCE_COLUMN\")\n",
    "if hint_conf_col:\n",
    "    if hint_conf_col in raw_df.columns:\n",
    "        raw_df[hint_conf_col] = raw_df[hint_conf_col].fillna(0.0).astype(float)\n",
    "    else:\n",
    "        raw_df[hint_conf_col] = 0.0\n",
    "\n",
    "print(f\"Корпус: {len(raw_df)} сегментов\")\n",
    "if hint_col:\n",
    "    hint_counts = raw_df[hint_col].value_counts(dropna=False).sort_index()\n",
    "    display(hint_counts.rename(\"rows\"))\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c25c4",
   "metadata": {},
   "source": [
    "## Подбор zero-shot модели\n",
    "\n",
    "Сравним несколько моделей по точности на небольшом подмножестве корпуса и выберем лучшую для генерации seed-меток.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367331d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117648/2710994355.py:21: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(min(len(g), per_class), random_state=config[\"SEED\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: joeddav/xlm-roberta-large-xnli\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98fc7f088504584a4e8298c5442b909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/734 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90a4ad6ca5e4040b07868894bb0f8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:629\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[39m\n\u001b[32m    627\u001b[39m     progress.update(progress_bytes)\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m \u001b[43mdownload_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxet_download_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpiration_unix_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_refresher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprogress_updater\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Xet Runtime Error: Task cancelled; possible runtime shutdown in progress (task 13 was cancelled).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mМодель: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     clf = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzero-shot-classification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:  \u001b[38;5;66;03m# noqa: BLE001\u001b[39;00m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[WARN] Пропускаем модель \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:1027\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1037\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m# Check which preprocessing classes the pipeline uses\u001b[39;00m\n\u001b[32m   1040\u001b[39m \u001b[38;5;66;03m# None values indicate optional classes that the pipeline can run without, we don't raise errors if loading fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/pipelines/base.py:293\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    287\u001b[39m     logger.warning(\n\u001b[32m    288\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to load the model with Tensorflow.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    290\u001b[39m     )\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     model = \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33meval\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    295\u001b[39m         model = model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4903\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4893\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4894\u001b[39m     gguf_file\n\u001b[32m   4895\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4896\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4897\u001b[39m ):\n\u001b[32m   4898\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4899\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4900\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4901\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4903\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4916\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4923\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4924\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:1041\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1027\u001b[39m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[32m   1028\u001b[39m     cached_file_kwargs = {\n\u001b[32m   1029\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcache_dir\u001b[39m\u001b[33m\"\u001b[39m: cache_dir,\n\u001b[32m   1030\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mforce_download\u001b[39m\u001b[33m\"\u001b[39m: force_download,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1039\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m: commit_hash,\n\u001b[32m   1040\u001b[39m     }\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m     resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1043\u001b[39m     \u001b[38;5;66;03m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;66;03m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[32m   1045\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[32m   1046\u001b[39m         \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m         snapshot_download(\n\u001b[32m    495\u001b[39m             path_or_repo_id,\n\u001b[32m    496\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    506\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1010\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    990\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    991\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    992\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1008\u001b[39m     )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1171\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1184\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1723\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[32m   1722\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1723\u001b[39m     \u001b[43mxet_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplayed_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1731\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:624\u001b[39m, in \u001b[36mxet_get\u001b[39m\u001b[34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[39m\n\u001b[32m    613\u001b[39m     displayed_filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[32m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(…)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m progress_cm = _get_progress_bar_context(\n\u001b[32m    616\u001b[39m     desc=displayed_filename,\n\u001b[32m    617\u001b[39m     log_level=logger.getEffectiveLevel(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    621\u001b[39m     _tqdm_bar=_tqdm_bar,\n\u001b[32m    622\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress_cm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mprogress_updater\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/hw_nlp/.venv/lib/python3.12/site-packages/tqdm/std.py:1138\u001b[39m, in \u001b[36mtqdm.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "label_names = list(config[\"LABEL_NAMES\"].values())\n",
    "inverse_label = {name: idx for idx, name in config[\"LABEL_NAMES\"].items()}\n",
    "\n",
    "candidate_models = config.get(\"ZERO_SHOT_MODELS\", [])\n",
    "if not candidate_models:\n",
    "    raise ValueError(\"Список ZERO_SHOT_MODELS в конфиге пуст.\")\n",
    "\n",
    "hint_col = config.get(\"HINT_COLUMN\")\n",
    "if hint_col is None or hint_col not in raw_df.columns:\n",
    "    raise RuntimeError(\"Нет эвристических подсказок (style hints) для оценки zero-shot моделей.\")\n",
    "\n",
    "hint_mask = raw_df[hint_col] >= 0\n",
    "if not hint_mask.any():\n",
    "    raise RuntimeError(\"Эвристические подсказки отсутствуют, нечем калибровать zero-shot модель.\")\n",
    "\n",
    "eval_pool = raw_df[hint_mask].copy()\n",
    "num_classes = max(1, eval_pool[hint_col].nunique())\n",
    "per_class = max(1, config[\"ZERO_SHOT_SAMPLE_SIZE\"] // num_classes)\n",
    "eval_df = (\n",
    "    eval_pool.groupby(hint_col, group_keys=False)\n",
    "    .apply(lambda g: g.sample(min(len(g), per_class), random_state=config[\"SEED\"]))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "eval_df = eval_df.sample(min(len(eval_df), config[\"ZERO_SHOT_SAMPLE_SIZE\"]), random_state=config[\"SEED\"]).reset_index(drop=True)\n",
    "\n",
    "evaluation_results = []\n",
    "device_index = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "for model_name in candidate_models:\n",
    "    print(f\"Модель: {model_name}\")\n",
    "    try:\n",
    "        clf = pipeline(\"zero-shot-classification\", model=model_name, device=device_index)\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        print(f\"[WARN] Пропускаем модель {model_name}: {exc}\")\n",
    "        evaluation_results.append(\n",
    "            {\n",
    "                \"model\": model_name,\n",
    "                \"accuracy\": np.nan,\n",
    "                \"macro_f1\": np.nan,\n",
    "                \"mean_confidence\": np.nan,\n",
    "                \"samples\": 0,\n",
    "                \"error\": str(exc),\n",
    "            }\n",
    "        )\n",
    "        continue\n",
    "    preds = []\n",
    "    scores = []\n",
    "    batch_size = 8\n",
    "    total_batches = math.ceil(len(eval_df) / batch_size)\n",
    "    for start in tqdm(range(0, len(eval_df), batch_size), total=total_batches, desc=\"Inference\", unit=\"batch\"):\n",
    "        batch = eval_df.iloc[start : start + batch_size]\n",
    "        outputs = clf(list(batch[config[\"TEXT_COLUMN\"]]), candidate_labels=label_names)\n",
    "        if isinstance(outputs, dict):\n",
    "            outputs = [outputs]\n",
    "        for out in outputs:\n",
    "            label_name = out[\"labels\"][0]\n",
    "            label_idx = inverse_label.get(label_name)\n",
    "            if label_idx is None:\n",
    "                continue\n",
    "            preds.append(label_idx)\n",
    "            scores.append(float(out[\"scores\"][0]))\n",
    "    if not preds:\n",
    "        del clf\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        continue\n",
    "    acc = accuracy_score(eval_df[hint_col].iloc[: len(preds)], preds)\n",
    "    macro_f1 = f1_score(eval_df[hint_col].iloc[: len(preds)], preds, average=\"macro\")\n",
    "    mean_conf = float(np.mean(scores)) if scores else 0.0\n",
    "    evaluation_results.append(\n",
    "        {\n",
    "            \"model\": model_name,\n",
    "            \"accuracy\": acc,\n",
    "            \"macro_f1\": macro_f1,\n",
    "            \"mean_confidence\": mean_conf,\n",
    "            \"samples\": len(preds),\n",
    "        }\n",
    "    )\n",
    "    del clf\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "evaluation_df = pd.DataFrame(evaluation_results)\n",
    "if not evaluation_df.empty:\n",
    "    evaluation_df = evaluation_df.sort_values(\"macro_f1\", ascending=False)\n",
    "display(evaluation_df)\n",
    "\n",
    "valid_df = evaluation_df.dropna(subset=[\"macro_f1\"]) if not evaluation_df.empty else evaluation_df\n",
    "if not valid_df.empty:\n",
    "    best_model_name = valid_df.iloc[0][\"model\"]\n",
    "    print(f\"Лучший zero-shot (по согласию с эвристикой): {best_model_name}\")\n",
    "    config[\"ZERO_SHOT_MODEL\"] = best_model_name\n",
    "else:\n",
    "    print(\"Не удалось подобрать zero-shot модель. Проверьте список ZERO_SHOT_MODELS.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d833cc48",
   "metadata": {},
   "source": [
    "## Seed через zero-shot / LLM\n",
    "\n",
    "1. Сэмплируем сбалансированный seed.\n",
    "2. Прогоняем через zero-shot модель (`transformers.pipeline`).\n",
    "3. Фильтруем по порогу уверенности и сохраняем в `seed_labels.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85214ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed размер: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_30888/1159421413.py:11: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.sample(min(len(g), per_class), random_state=config[\"SEED\"]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_archive",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source_file",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "meta_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "meta_title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_languages",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "meta_textid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_rubric",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_region",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "meta_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "meta_tags",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "style_hint_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "style_hint",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "style_hint_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "style_hint_source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5caaf8dd-9ca9-42a2-b1be-dcb6f35f0014",
       "rows": [
        [
         "0",
         "Вы нихуя не понимаете в Ельцине! Он был эпичен и велик. Ельцин взял и поимел Советский Союз. Ельцин приехал в США и насрав на все их правила и обычаи накатил и весело станцивал наглядно демонстрируя свою отношение к \"великой Америке\". Я, БЛЯДЬ ПРИБЫЛ В ВАШИНГТОН С ДВУМЯ ЧЕМОДАНАМИ В РУКАХ. В ОДНОМ У МЕНЯ ДВЕ БУТЫЛКИ ВОДКИ И БАНКА ОГУРЦОВ, А В ДРУГОМ КРАСНАЯ КНОПКА.",
         "social.tar.gz",
         "home/tsha/social/texts/vktexts.txt#entry25570",
         "25570",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "разговорный стиль",
         "0.6",
         "archive"
        ],
        [
         "1",
         "Петушки, видящие в трампе эдакого американского Жириновского/агента Путина/будущего друга России - заслуживают напористой желтой струи в лицо.",
         "social.tar.gz",
         "home/tsha/social/texts/vktexts.txt#entry241406",
         "241406",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "разговорный стиль",
         "0.6",
         "archive"
        ],
        [
         "2",
         "Едро, лдпр, комуняги и справедливоросы 45%, 50% овощей. Ребята да вы мазахисты, об вас 20 лет ноги вытирают, а вы все туда же...",
         "social.tar.gz",
         "home/tsha/social/texts/vktexts.txt#entry259224",
         "259224",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "разговорный стиль",
         "0.6",
         "archive"
        ],
        [
         "3",
         "Я еще предлагаю что бы активисты закидали письмами администрацию президента . что бы этой семье помогли и сняли с поста нашего \"любимого мэра\".я сегодня же напишу.Пусть порадуются Едро за своих",
         "social.tar.gz",
         "home/tsha/social/texts/vktexts.txt#entry184724",
         "184724",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "разговорный стиль",
         "0.6",
         "archive"
        ],
        [
         "4",
         "Ну в \"Единой России\" хотя бы шевеления происходят, помимо выполнения неких обязанностей, они и состав меняют, показывая, что свежие умы, всегда лучше.",
         "social.tar.gz",
         "home/tsha/social/texts/vktexts.txt#entry68069",
         "68069",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         "0",
         "разговорный стиль",
         "0.6",
         "archive"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source_archive</th>\n",
       "      <th>source_file</th>\n",
       "      <th>meta_id</th>\n",
       "      <th>meta_title</th>\n",
       "      <th>meta_languages</th>\n",
       "      <th>meta_textid</th>\n",
       "      <th>meta_rubric</th>\n",
       "      <th>meta_region</th>\n",
       "      <th>meta_date</th>\n",
       "      <th>meta_tags</th>\n",
       "      <th>style_hint_label</th>\n",
       "      <th>style_hint</th>\n",
       "      <th>style_hint_confidence</th>\n",
       "      <th>style_hint_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вы нихуя не понимаете в Ельцине! Он был эпичен...</td>\n",
       "      <td>social.tar.gz</td>\n",
       "      <td>home/tsha/social/texts/vktexts.txt#entry25570</td>\n",
       "      <td>25570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Петушки, видящие в трампе эдакого американског...</td>\n",
       "      <td>social.tar.gz</td>\n",
       "      <td>home/tsha/social/texts/vktexts.txt#entry241406</td>\n",
       "      <td>241406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Едро, лдпр, комуняги и справедливоросы 45%, 50...</td>\n",
       "      <td>social.tar.gz</td>\n",
       "      <td>home/tsha/social/texts/vktexts.txt#entry259224</td>\n",
       "      <td>259224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Я еще предлагаю что бы активисты закидали пись...</td>\n",
       "      <td>social.tar.gz</td>\n",
       "      <td>home/tsha/social/texts/vktexts.txt#entry184724</td>\n",
       "      <td>184724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ну в \"Единой России\" хотя бы шевеления происхо...</td>\n",
       "      <td>social.tar.gz</td>\n",
       "      <td>home/tsha/social/texts/vktexts.txt#entry68069</td>\n",
       "      <td>68069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>archive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source_archive  \\\n",
       "0  Вы нихуя не понимаете в Ельцине! Он был эпичен...  social.tar.gz   \n",
       "1  Петушки, видящие в трампе эдакого американског...  social.tar.gz   \n",
       "2  Едро, лдпр, комуняги и справедливоросы 45%, 50...  social.tar.gz   \n",
       "3  Я еще предлагаю что бы активисты закидали пись...  social.tar.gz   \n",
       "4  Ну в \"Единой России\" хотя бы шевеления происхо...  social.tar.gz   \n",
       "\n",
       "                                      source_file meta_id meta_title  \\\n",
       "0   home/tsha/social/texts/vktexts.txt#entry25570   25570        NaN   \n",
       "1  home/tsha/social/texts/vktexts.txt#entry241406  241406        NaN   \n",
       "2  home/tsha/social/texts/vktexts.txt#entry259224  259224        NaN   \n",
       "3  home/tsha/social/texts/vktexts.txt#entry184724  184724        NaN   \n",
       "4   home/tsha/social/texts/vktexts.txt#entry68069   68069        NaN   \n",
       "\n",
       "   meta_languages meta_textid meta_rubric  meta_region meta_date meta_tags  \\\n",
       "0             NaN         NaN         NaN          NaN       NaN       NaN   \n",
       "1             NaN         NaN         NaN          NaN       NaN       NaN   \n",
       "2             NaN         NaN         NaN          NaN       NaN       NaN   \n",
       "3             NaN         NaN         NaN          NaN       NaN       NaN   \n",
       "4             NaN         NaN         NaN          NaN       NaN       NaN   \n",
       "\n",
       "   style_hint_label         style_hint  style_hint_confidence  \\\n",
       "0                 0  разговорный стиль                    0.6   \n",
       "1                 0  разговорный стиль                    0.6   \n",
       "2                 0  разговорный стиль                    0.6   \n",
       "3                 0  разговорный стиль                    0.6   \n",
       "4                 0  разговорный стиль                    0.6   \n",
       "\n",
       "  style_hint_source  \n",
       "0           archive  \n",
       "1           archive  \n",
       "2           archive  \n",
       "3           archive  \n",
       "4           archive  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hint_col = config.get(\"HINT_COLUMN\")\n",
    "hint_mask = (raw_df[hint_col] >= 0) if hint_col else pd.Series(False, index=raw_df.index)\n",
    "target_seed = min(len(raw_df), config[\"ZERO_SHOT_SAMPLE_SIZE\"])\n",
    "\n",
    "if hint_col and hint_mask.any():\n",
    "    classes = max(1, raw_df.loc[hint_mask, hint_col].nunique())\n",
    "    per_class = max(1, target_seed // classes)\n",
    "    seed_df = (\n",
    "        raw_df.loc[hint_mask]\n",
    "        .groupby(hint_col, group_keys=False)\n",
    "        .apply(lambda g: g.sample(min(len(g), per_class), random_state=config[\"SEED\"]))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    remaining = target_seed - len(seed_df)\n",
    "    if remaining > 0:\n",
    "        remainder = raw_df.loc[~hint_mask]\n",
    "        if not remainder.empty:\n",
    "            extra = remainder.sample(min(len(remainder), remaining), random_state=config[\"SEED\"])\n",
    "            seed_df = pd.concat([seed_df, extra], ignore_index=True)\n",
    "else:\n",
    "    seed_df = raw_df.sample(target_seed, random_state=config[\"SEED\"]).reset_index(drop=True)\n",
    "\n",
    "seed_df = seed_df.sample(frac=1.0, random_state=config[\"SEED\"]).reset_index(drop=True)\n",
    "print(f\"Seed размер: {len(seed_df)}\")\n",
    "seed_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c9fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cuda:0\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.zero_shot_classification.ZeroShotClassificationPipeline at 0x7c4273aa26f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot = None\n",
    "try:\n",
    "    zero_shot = pipeline(\n",
    "        \"zero-shot-classification\",\n",
    "        model=config[\"ZERO_SHOT_MODEL\"],\n",
    "        device=0 if torch.cuda.is_available() else -1,\n",
    "    )\n",
    "except Exception as exc:  # noqa: BLE001\n",
    "    print(f\"[WARN] Не удалось загрузить zero-shot модель {config['ZERO_SHOT_MODEL']}: {exc}\")\n",
    "zero_shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031ad73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df54fceb6654979961036758ba670d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Zero-shot inference:   0%|          | 0/375 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pred_label_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "pred_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pred_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "second_best",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hint_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hint_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hint_confidence",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hint_agrees",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "source_archive",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "2ae373b4-83f9-42da-9642-33fa00dad1f2",
       "rows": [
        [
         "0",
         "Вы нихуя не понимаете в Ельцине! Он был эпичен и велик. Ельцин взял и поимел Советский Союз. Ельцин приехал в США и насрав на все их правила и обычаи накатил и весело станцивал наглядно демонстрируя свою отношение к \"великой Америке\". Я, БЛЯДЬ ПРИБЫЛ В ВАШИНГТОН С ДВУМЯ ЧЕМОДАНАМИ В РУКАХ. В ОДНОМ У МЕНЯ ДВЕ БУТЫЛКИ ВОДКИ И БАНКА ОГУРЦОВ, А В ДРУГОМ КРАСНАЯ КНОПКА.",
         "разговорный стиль",
         "0",
         "0.5155879259109497",
         "официально-деловой стиль",
         "0",
         "разговорный стиль",
         "0.6",
         "True",
         "social.tar.gz"
        ],
        [
         "1",
         "Петушки, видящие в трампе эдакого американского Жириновского/агента Путина/будущего друга России - заслуживают напористой желтой струи в лицо.",
         "разговорный стиль",
         "0",
         "0.5031546354293823",
         "официально-деловой стиль",
         "0",
         "разговорный стиль",
         "0.6",
         "True",
         "social.tar.gz"
        ],
        [
         "2",
         "Едро, лдпр, комуняги и справедливоросы 45%, 50% овощей. Ребята да вы мазахисты, об вас 20 лет ноги вытирают, а вы все туда же...",
         "разговорный стиль",
         "0",
         "0.5077944397926331",
         "официально-деловой стиль",
         "0",
         "разговорный стиль",
         "0.6",
         "True",
         "social.tar.gz"
        ],
        [
         "3",
         "Я еще предлагаю что бы активисты закидали письмами администрацию президента . что бы этой семье помогли и сняли с поста нашего \"любимого мэра\".я сегодня же напишу.Пусть порадуются Едро за своих",
         "разговорный стиль",
         "0",
         "0.5066509246826172",
         "официально-деловой стиль",
         "0",
         "разговорный стиль",
         "0.6",
         "True",
         "social.tar.gz"
        ],
        [
         "4",
         "Ну в \"Единой России\" хотя бы шевеления происходят, помимо выполнения неких обязанностей, они и состав меняют, показывая, что свежие умы, всегда лучше.",
         "разговорный стиль",
         "0",
         "0.5020827651023865",
         "официально-деловой стиль",
         "0",
         "разговорный стиль",
         "0.6",
         "True",
         "social.tar.gz"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pred_label_name</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_score</th>\n",
       "      <th>second_best</th>\n",
       "      <th>hint_label</th>\n",
       "      <th>hint_name</th>\n",
       "      <th>hint_confidence</th>\n",
       "      <th>hint_agrees</th>\n",
       "      <th>source_archive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Вы нихуя не понимаете в Ельцине! Он был эпичен...</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515588</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>social.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Петушки, видящие в трампе эдакого американског...</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503155</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>social.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Едро, лдпр, комуняги и справедливоросы 45%, 50...</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507794</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>social.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Я еще предлагаю что бы активисты закидали пись...</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506651</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>social.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ну в \"Единой России\" хотя бы шевеления происхо...</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502083</td>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>0</td>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>0.6</td>\n",
       "      <td>True</td>\n",
       "      <td>social.tar.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    pred_label_name  \\\n",
       "0  Вы нихуя не понимаете в Ельцине! Он был эпичен...  разговорный стиль   \n",
       "1  Петушки, видящие в трампе эдакого американског...  разговорный стиль   \n",
       "2  Едро, лдпр, комуняги и справедливоросы 45%, 50...  разговорный стиль   \n",
       "3  Я еще предлагаю что бы активисты закидали пись...  разговорный стиль   \n",
       "4  Ну в \"Единой России\" хотя бы шевеления происхо...  разговорный стиль   \n",
       "\n",
       "   pred_label  pred_score               second_best  hint_label  \\\n",
       "0           0    0.515588  официально-деловой стиль           0   \n",
       "1           0    0.503155  официально-деловой стиль           0   \n",
       "2           0    0.507794  официально-деловой стиль           0   \n",
       "3           0    0.506651  официально-деловой стиль           0   \n",
       "4           0    0.502083  официально-деловой стиль           0   \n",
       "\n",
       "           hint_name  hint_confidence  hint_agrees source_archive  \n",
       "0  разговорный стиль              0.6         True  social.tar.gz  \n",
       "1  разговорный стиль              0.6         True  social.tar.gz  \n",
       "2  разговорный стиль              0.6         True  social.tar.gz  \n",
       "3  разговорный стиль              0.6         True  social.tar.gz  \n",
       "4  разговорный стиль              0.6         True  social.tar.gz  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions: List[Dict[str, object]] = []\n",
    "\n",
    "if zero_shot is None:\n",
    "    print(\"Zero-shot модель не загружена, пропускаем инференс.\")\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "else:\n",
    "    batch_size = 8\n",
    "    total_batches = math.ceil(len(seed_df) / batch_size)\n",
    "    hint_col = config.get(\"HINT_COLUMN\")\n",
    "    hint_name_col = config.get(\"HINT_NAME_COLUMN\")\n",
    "    hint_conf_col = config.get(\"HINT_CONFIDENCE_COLUMN\")\n",
    "    for start in tqdm(\n",
    "        range(0, len(seed_df), batch_size),\n",
    "        total=total_batches,\n",
    "        desc=\"Zero-shot inference\",\n",
    "        unit=\"batch\",\n",
    "    ):\n",
    "        batch = seed_df.iloc[start : start + batch_size]\n",
    "        outputs = zero_shot(list(batch[config[\"TEXT_COLUMN\"]]), candidate_labels=label_names)\n",
    "        if isinstance(outputs, dict):  # когда размер batch=1\n",
    "            outputs = [outputs]\n",
    "        for row, out in zip(batch.itertuples(index=False), outputs):\n",
    "            label_name = out[\"labels\"][0]\n",
    "            pred_label = inverse_label.get(label_name)\n",
    "            if pred_label is None:\n",
    "                continue\n",
    "            pred_score = float(out[\"scores\"][0])\n",
    "            second = out[\"labels\"][1] if len(out[\"labels\"]) > 1 else None\n",
    "            hint_label = getattr(row, hint_col, -1) if hint_col else -1\n",
    "            hint_name = getattr(row, hint_name_col, \"\") if hint_name_col else \"\"\n",
    "            if hint_conf_col and hasattr(row, hint_conf_col):\n",
    "                hint_conf = float(getattr(row, hint_conf_col))\n",
    "            else:\n",
    "                hint_conf = None\n",
    "            hint_agree = (hint_label == pred_label) if hint_label is not None and hint_label >= 0 else None\n",
    "            predictions.append(\n",
    "                {\n",
    "                    \"text\": getattr(row, config[\"TEXT_COLUMN\"]),\n",
    "                    \"pred_label_name\": label_name,\n",
    "                    \"pred_label\": pred_label,\n",
    "                    \"pred_score\": pred_score,\n",
    "                    \"second_best\": second,\n",
    "                    \"hint_label\": hint_label,\n",
    "                    \"hint_name\": hint_name,\n",
    "                    \"hint_confidence\": hint_conf,\n",
    "                    \"hint_agrees\": hint_agree,\n",
    "                    \"source_archive\": getattr(row, \"source_archive\", \"\"),\n",
    "                }\n",
    "            )\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23677689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фильтр по уверенности 0.48: оставлено 3000 примеров\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pred_label_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hint_agrees",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "max",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "6986faf4-f3f1-4184-bfa6-f85ab498962d",
       "rows": [
        [
         "0",
         "официально-деловой стиль",
         "False",
         "222",
         "0.5031194128431715",
         "0.5000486373901367",
         "0.5140172839164734"
        ],
        [
         "1",
         "официально-деловой стиль",
         "True",
         "245",
         "0.5049181062348035",
         "0.5000585913658142",
         "0.520886242389679"
        ],
        [
         "2",
         "разговорный стиль",
         "False",
         "1255",
         "0.5056616529050576",
         "0.5000131726264954",
         "0.5284749865531921"
        ],
        [
         "3",
         "разговорный стиль",
         "True",
         "1278",
         "0.5052667429935951",
         "0.5000031590461731",
         "0.5269506573677063"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label_name</th>\n",
       "      <th>hint_agrees</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>False</td>\n",
       "      <td>222</td>\n",
       "      <td>0.503119</td>\n",
       "      <td>0.500049</td>\n",
       "      <td>0.514017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>официально-деловой стиль</td>\n",
       "      <td>True</td>\n",
       "      <td>245</td>\n",
       "      <td>0.504918</td>\n",
       "      <td>0.500059</td>\n",
       "      <td>0.520886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>False</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.505662</td>\n",
       "      <td>0.500013</td>\n",
       "      <td>0.528475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>разговорный стиль</td>\n",
       "      <td>True</td>\n",
       "      <td>1278</td>\n",
       "      <td>0.505267</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.526951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pred_label_name  hint_agrees  count      mean       min       max\n",
       "0  официально-деловой стиль        False    222  0.503119  0.500049  0.514017\n",
       "1  официально-деловой стиль         True    245  0.504918  0.500059  0.520886\n",
       "2         разговорный стиль        False   1255  0.505662  0.500013  0.528475\n",
       "3         разговорный стиль         True   1278  0.505267  0.500003  0.526951"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed сохранён в cache_boosted/autolabel/seed_labels.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = config[\"ZERO_SHOT_THRESHOLD\"]\n",
    "seed_filtered = pred_df[pred_df[\"pred_score\"] >= threshold].copy()\n",
    "print(f\"Фильтр по уверенности {threshold:.2f}: оставлено {len(seed_filtered)} примеров\")\n",
    "if not seed_filtered.empty:\n",
    "    group_cols = [\"pred_label_name\", \"hint_agrees\"]\n",
    "    agg = (\n",
    "        seed_filtered.groupby(group_cols)[\"pred_score\"]\n",
    "        .agg([\"count\", \"mean\", \"min\", \"max\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    display(agg)\n",
    "\n",
    "seed_path = AUTOLABEL_DIR / \"seed_labels.csv\"\n",
    "seed_filtered.to_csv(seed_path, index=False)\n",
    "print(f\"Seed сохранён в {seed_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615e80f",
   "metadata": {},
   "source": [
    "## Fine-tuning RuBERT на seed\n",
    "\n",
    "Теперь обучаем компактный классификатор, чтобы перенести стилистические метки на весь корпус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef34751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2549, Val: 451\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed_for_train = seed_filtered.copy()\n",
    "autolabel_ready = True\n",
    "\n",
    "if \"pred_label\" in seed_for_train.columns and not seed_for_train.empty:\n",
    "    seed_for_train[\"label\"] = seed_for_train[\"pred_label\"].astype(int)\n",
    "else:\n",
    "    seed_for_train[\"label\"] = pd.Series(index=seed_for_train.index, dtype=int)\n",
    "\n",
    "label_counts = seed_for_train[\"label\"].value_counts()\n",
    "class_count = int(len(label_counts))\n",
    "if seed_for_train.empty:\n",
    "    print(\"[WARN] Seed пуст: zero-shot не дал ни одного примера. Обучение пропускаем.\")\n",
    "    autolabel_ready = False\n",
    "elif class_count < 2:\n",
    "    print(\"[WARN] Seed содержит менее двух классов. Невозможно обучить классификатор, пропускаем обучение.\")\n",
    "    autolabel_ready = False\n",
    "elif label_counts.min() < 2:\n",
    "    print(\"[WARN] Для хотя бы одного класса слишком мало примеров для стратификации. Обучение пропускаем.\")\n",
    "    autolabel_ready = False\n",
    "else:\n",
    "    try:\n",
    "        train_df, val_df = train_test_split(\n",
    "            seed_for_train,\n",
    "            test_size=1 - config[\"TRAIN_SIZE\"],\n",
    "            stratify=seed_for_train[\"label\"],\n",
    "            random_state=config[\"SEED\"],\n",
    "        )\n",
    "        train_df = train_df.reset_index(drop=True)\n",
    "        val_df = val_df.reset_index(drop=True)\n",
    "        print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "    except ValueError as exc:  # например, слишком мало объектов на класс\n",
    "        print(f\"[WARN] Не удалось разбить seed: {exc}\")\n",
    "        autolabel_ready = False\n",
    "\n",
    "if not autolabel_ready:\n",
    "    train_df = seed_for_train.reset_index(drop=True)\n",
    "    val_df = seed_for_train.iloc[0:0].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a3d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config[\"BERT_BASE_MODEL\"])\n",
    "\n",
    "@dataclass\n",
    "class StyleDataset:\n",
    "    df: pd.DataFrame\n",
    "    tokenizer: AutoTokenizer\n",
    "    text_column: str\n",
    "    label_column: str\n",
    "    max_length: int\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        row = self.df.iloc[idx]\n",
    "        encoded = self.tokenizer(\n",
    "            row[self.text_column],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "        )\n",
    "        encoded[\"labels\"] = int(row[self.label_column])\n",
    "        return {key: torch.tensor(val) for key, val in encoded.items()}\n",
    "\n",
    "train_dataset = StyleDataset(train_df.reset_index(drop=True), tokenizer, config[\"TEXT_COLUMN\"], \"label\", config[\"MAX_LENGTH\"])\n",
    "val_dataset = StyleDataset(val_df.reset_index(drop=True), tokenizer, config[\"TEXT_COLUMN\"], \"label\", config[\"MAX_LENGTH\"])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ad33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_30888/771381291.py:51: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.trainer.Trainer at 0x7c4273eb49e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not autolabel_ready or train_df.empty:\n",
    "    print(\"[WARN] Недостаточно seed-данных для обучения BERT. Пропускаем тренировку.\")\n",
    "    trainer = None\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        config[\"BERT_BASE_MODEL\"],\n",
    "        num_labels=len(config[\"LABEL_NAMES\"]),\n",
    "    )\n",
    "\n",
    "    from inspect import signature\n",
    "\n",
    "    # TrainingArguments API меняется между версиями transformers; подбираем поддерживаемые ключи\n",
    "    sig_params = set(signature(TrainingArguments.__init__).parameters)\n",
    "\n",
    "    def _set_first(names, value, target):\n",
    "        for name in names:\n",
    "            if name in sig_params:\n",
    "                target[name] = value\n",
    "                break\n",
    "\n",
    "    training_kwargs = {\n",
    "        \"output_dir\": str(AUTOLABEL_DIR / \"rubert_autolabel\"),\n",
    "    }\n",
    "\n",
    "    _set_first((\"evaluation_strategy\", \"eval_strategy\"), \"epoch\", training_kwargs)\n",
    "    _set_first((\"save_strategy\", \"save_strategy\"), \"epoch\", training_kwargs)\n",
    "\n",
    "    for key, value in [\n",
    "        (\"learning_rate\", 2e-5),\n",
    "        (\"per_device_train_batch_size\", 16),\n",
    "        (\"per_device_eval_batch_size\", 16),\n",
    "        (\"num_train_epochs\", 3),\n",
    "        (\"weight_decay\", 0.01),\n",
    "        (\"report_to\", \"none\"),\n",
    "        (\"load_best_model_at_end\", True),\n",
    "        (\"metric_for_best_model\", \"macro_f1\"),\n",
    "    ]:\n",
    "        if key in sig_params:\n",
    "            training_kwargs[key] = value\n",
    "\n",
    "    training_args = TrainingArguments(**training_kwargs)\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = logits.argmax(axis=-1)\n",
    "        return {\n",
    "            \"accuracy\": accuracy_score(labels, preds),\n",
    "            \"macro_f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        }\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab12101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer готов. Раскомментируйте строку ниже, чтобы запустить обучение.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='480' max='480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [480/480 00:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.397663</td>\n",
       "      <td>0.822616</td>\n",
       "      <td>0.572390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.423924</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.587804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.473974</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.605904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if trainer is None:\n",
    "    print(\"[WARN] Тренировочный пайплайн не инициализирован: нет данных для обучения.\")\n",
    "else:\n",
    "    print(\"Trainer готов. Раскомментируйте строку ниже, чтобы запустить обучение.\")\n",
    "    trainer.train()\n",
    "    # После обучения можно сохранить модель:\n",
    "    trainer.save_model(AUTOLABEL_DIR / \"rubert_autolabel/best_model\")\n",
    "    tokenizer.save_pretrained(AUTOLABEL_DIR / \"rubert_autolabel/best_model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacaf8c",
   "metadata": {},
   "source": [
    "## Применение модели и активное обучение\n",
    "\n",
    "- Применяем обученную модель ко всему корпусу.\n",
    "- Сохраняем псевдометки + вероятность.\n",
    "- Формируем пул сомнительных текстов для дополнительной проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832a7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce61956ee394d91bf4659b65ccb70a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model inference:   0%|          | 0/250 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 579 примеров сохранены для ручной проверки → cache_boosted/autolabel/manual_review_candidates.csv\n",
      "[INFO] Отфильтрованы слабые псевдометки: 16000 → 14758 (порог 0.70).\n",
      "Псевдометки сохранены в cache_boosted/autolabel/pseudo_labels.csv\n"
     ]
    }
   ],
   "source": [
    "from typing import TYPE_CHECKING, Dict, List\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from transformers import AutoTokenizer\n",
    "\n",
    "# Глобальные объекты задаются в предыдущих ячейках; типы нужны для анализаторов\n",
    "config: Dict[str, object]\n",
    "tokenizer: \"AutoTokenizer\"\n",
    "\n",
    "\n",
    "def predict_proba(model: AutoModelForSequenceClassification, texts: List[str], batch_size: int = 64) -> np.ndarray:\n",
    "    model.eval()\n",
    "    probs: List[np.ndarray] = []\n",
    "    with torch.no_grad():\n",
    "        total_batches = math.ceil(len(texts) / batch_size)\n",
    "        for start in tqdm(\n",
    "            range(0, len(texts), batch_size),\n",
    "            total=total_batches,\n",
    "            desc=\"Model inference\",\n",
    "            unit=\"batch\",\n",
    "        ):\n",
    "            batch = texts[start : start + batch_size]\n",
    "            enc = tokenizer(\n",
    "                batch,\n",
    "                truncation=True,\n",
    "                max_length=config[\"MAX_LENGTH\"],\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(model.device)\n",
    "            logits = model(**enc).logits\n",
    "            probs.append(logits.softmax(dim=-1).cpu().numpy())\n",
    "    return np.concatenate(probs, axis=0)\n",
    "\n",
    "# Пример использования после обучения: считаем уверенности, фильтруем и сохраняем.\n",
    "full_probs = predict_proba(trainer.model, raw_df[config[\"TEXT_COLUMN\"]].tolist())\n",
    "\n",
    "pseudo_df = raw_df.copy()\n",
    "pseudo_df[\"pseudo_label\"] = full_probs.argmax(axis=1)\n",
    "pseudo_df[\"pseudo_confidence\"] = full_probs.max(axis=1)\n",
    "\n",
    "manual_threshold = 0.6  # записи ниже этого порога удобнее отдать на ручную проверку\n",
    "low_conf_mask = pseudo_df[\"pseudo_confidence\"] < manual_threshold\n",
    "if low_conf_mask.any():\n",
    "    review_path = AUTOLABEL_DIR / \"manual_review_candidates.csv\"\n",
    "    pseudo_df.loc[low_conf_mask].to_csv(review_path, index=False)\n",
    "    print(f\"[INFO] {low_conf_mask.sum()} примеров сохранены для ручной проверки → {review_path}\")\n",
    "\n",
    "min_conf = float(config.get(\"PSEUDO_MIN_CONF\", 0.0) or 0.0)\n",
    "if min_conf > 0:\n",
    "    before = len(pseudo_df)\n",
    "    pseudo_df = pseudo_df[pseudo_df[\"pseudo_confidence\"] >= min_conf].copy()\n",
    "    print(f\"[INFO] Отфильтрованы слабые псевдометки: {before} → {len(pseudo_df)} (порог {min_conf:.2f}).\")\n",
    "\n",
    "pseudo_path = AUTOLABEL_DIR / \"pseudo_labels.csv\"\n",
    "pseudo_df.to_csv(pseudo_path, index=False)\n",
    "print(f\"Псевдометки сохранены в {pseudo_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c122d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сомнительные примеры сохранены в cache_boosted/autolabel/uncertain_samples.csv. Используйте LLM/ручную проверку.\n"
     ]
    }
   ],
   "source": [
    "def select_uncertain_examples(df: pd.DataFrame, confidence_col: str, top_n: int = 200) -> pd.DataFrame:\n",
    "    \"\"\"Выбираем тексты с минимальной уверенностью для активного уточнения.\"\"\"\n",
    "    if confidence_col not in df.columns:\n",
    "        raise KeyError(f\"Колонка {confidence_col} отсутствует\")\n",
    "    return df.nsmallest(top_n, confidence_col)\n",
    "\n",
    "# Пример использования после псевдометок:\n",
    "uncertain = select_uncertain_examples(pseudo_df, 'pseudo_confidence', top_n=300)\n",
    "uncertain_path = AUTOLABEL_DIR / 'uncertain_samples.csv'\n",
    "uncertain.to_csv(uncertain_path, index=False)\n",
    "print(f'Сомнительные примеры сохранены в {uncertain_path}. Используйте LLM/ручную проверку.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что дальше\n",
    "\n",
    "1. Опционально дособрать seed через более мощную LLM и объединить с текущим.\n",
    "2. Запустить ячейки fine-tuning и псевдометок, получить финальный корпус для основной классификации.\n",
    "3. Повторять активное обучение до стабилизации метрик.\n",
    "4. Все артефакты лежат в `cache_boosted/autolabel`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
